{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we capture the variability in both precip. and prob. of precip. with a single NN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import Sampler\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "from torch.distributions import Beta\n",
    "import wandb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import matplotlib\n",
    "import datetime as dt\n",
    "import glob\n",
    "import bisect\n",
    "import zipfile\n",
    "\n",
    "from Data_loader import prc_norm, LoadTraining, Normalize, Custom_Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "# importlib.reload(Data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Declare directories ###\n",
    "\n",
    "PRECIP_ONLY=False\n",
    "if PRECIP_ONLY:\n",
    "    DIR_STR='precip_only/'\n",
    "else:\n",
    "    DIR_STR=''\n",
    "\n",
    "fils_lrh=glob.glob('/neelin2020/ML_input/gpm2a_dpr_era5/npy_files/{}lrh/lrh_*npy'.format(DIR_STR))\n",
    "fils_lrh.sort()\n",
    "\n",
    "fils_conv_prc=glob.glob('/neelin2020/ML_input/gpm2a_dpr_era5/npy_files/{}conv_rain/gpm_conv_rain_*npy'.format(DIR_STR))\n",
    "fils_conv_prc.sort()\n",
    "\n",
    "fils_imerg_prctm1=glob.glob('/neelin2020/ML_input/gpm2a_dpr_era5/npy_files/{}imerg_bk_rain/imerg_rain_bk_*npy'.format(DIR_STR))\n",
    "fils_imerg_prctm1.sort()\n",
    "\n",
    "fils_conv_nn=glob.glob('/neelin2020/ML_input/gpm2a_dpr_era5/npy_files/precip_only/{}gpm_conv_neighbor_rain_*npy'.format(DIR_STR))\n",
    "fils_conv_nn.sort()\n",
    "\n",
    "conv_prc_dir='/neelin2020/ML_input/gpm2a_dpr_era5/npy_files/{}conv_rain/'.format(DIR_STR)\n",
    "imerg_prc_tm1_dir='/neelin2020/ML_input/gpm2a_dpr_era5/npy_files/{}imerg_bk_rain/'.format(DIR_STR)\n",
    "conv_nn_dir='/neelin2020/ML_input/gpm2a_dpr_era5/npy_files/{}conv_nn_pr/'.format(DIR_STR)\n",
    "\n",
    "prc_norm_dict={'xbar':0,\n",
    "               'normalizer':prc_norm}\n",
    "\n",
    "# prc_norm_dict={'xbar':0,\n",
    "#                'normalizer':prc_log_std}\n",
    "\n",
    "\n",
    "lrh_norm_dict={'xbar':0,\n",
    "               'normalizer':1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=256\n",
    "transformed_samples=LoadTraining(fils_lrh[:150], conv_prc_dir, imerg_prc_tm1_dir, conv_nn_dir, \n",
    "                                 batch_size=BATCH_SIZE, \n",
    "                                 transform=Normalize(prc_norm_dict,lrh_norm_dict))\n",
    "\n",
    "custom_dataloader = torch.utils.data.DataLoader(transformed_samples, batch_size=None,\n",
    "                                                num_workers=6, \n",
    "                                                sampler=Custom_Sampler(len(transformed_samples),\n",
    "                                                                                      BATCH_SIZE,\n",
    "                                                                                      transformed_samples.array_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12680448 samples, 49533 batches\n"
     ]
    }
   ],
   "source": [
    "print(\" {:d} samples, {:d} batches\".format(len(transformed_samples),len(custom_dataloader))) ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check dataloader output ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = datetime.now()\n",
    "\n",
    "lrh=[]\n",
    "conv_prc=[]\n",
    "imerg_prc_tm1=[]\n",
    "conv_nn_prc=[]\n",
    "\n",
    "for i_batch, samples in enumerate(custom_dataloader):\n",
    "#     print(i_batch,samples)\n",
    "    lrh.append(samples['lrh'].detach().numpy())\n",
    "    conv_prc.append(samples['conv_prc'].detach().numpy())\n",
    "    imerg_prc_tm1.append(samples['imerg_prc_tm1'].detach().numpy())\n",
    "    conv_nn_prc.append(samples['conv_nn_prc'].detach().numpy())\n",
    "    \n",
    "    if i_batch==50:\n",
    "        break\n",
    "print(\"{:.2f} minutes\".format((datetime.now() - startTime).total_seconds()/60)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axx=plt.subplots(2,2,figsize=(10,5))\n",
    "\n",
    "ax=axx[0,0]\n",
    "ax.hist(np.concatenate(lrh).flatten())\n",
    "\n",
    "ax=axx[0,1]\n",
    "ax.hist(np.concatenate(conv_prc)*prc_norm.flatten())\n",
    "ax.set_yscale('log')\n",
    "\n",
    "ax=axx[1,0]\n",
    "ax.hist(np.concatenate(conv_nn_prc)*prc_norm.flatten())\n",
    "ax.set_yscale('log')\n",
    "\n",
    "ax=axx[1,1]\n",
    "ax.hist(np.concatenate(imerg_prc_tm1)*prc_norm.flatten())\n",
    "ax.set_yscale('log')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import VAE_models_CVAE_one_endec #as VAE\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'VAE_models_CVAE_one_endec' from '/home/fiaz/ML/vae/Exploring_latents/VAE_models_CVAE_one_endec.py'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(VAE_models_CVAE_one_endec)\n",
    "\n",
    "# sys.modules['VAE'] = VAE_models_CVAE_one_endec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIMS=2\n",
    "INPUT_DIMS=2\n",
    "NN_DIMS=4\n",
    "model=VAE_models_CVAE_one_endec.CVAE_ORG_mod(LATENT_DIMS,INPUT_DIMS,NN_DIMS).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['lrh', 'conv_prc', 'imerg_prc_tm1', 'conv_nn_prc'])\n",
      "zmax: 3.00\n",
      "shape: 3.19, scale: 1.00\n",
      "rain prob.: 0.79\n",
      "------------------------\n",
      "zmin: -3.00\n",
      "shape: 1.12, scale: 1.00\n",
      "rain prob.: 0.72\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "for i_batch, sample_batched in enumerate(custom_dataloader):\n",
    "    print(sample_batched.keys())\n",
    "    data=torch.stack((sample_batched['lrh'],\n",
    "                      sample_batched['conv_prc']),dim=1).unsqueeze(2)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    outputs=model(data)\n",
    "    kl_loss, binary_loss, gamma_loss=model.vae_loss(data.squeeze(),outputs,0)\n",
    "        \n",
    "    syn_size=1_000_000\n",
    "    z=torch.normal(mean=0.,std=1.,\n",
    "                                size=(syn_size,LATENT_DIMS))\n",
    "    VAE_models_CVAE_one_endec.print_params(z,model,torch.tensor([0.6]))\n",
    "\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfahmed\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/fiaz/ML/vae/Exploring_latents/wandb/run-20230508_094053-0w6yvnsw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fahmed/precip-VAE/runs/0w6yvnsw' target=\"_blank\">sparkling-silence-2</a></strong> to <a href='https://wandb.ai/fahmed/precip-VAE' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fahmed/precip-VAE' target=\"_blank\">https://wandb.ai/fahmed/precip-VAE</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fahmed/precip-VAE/runs/0w6yvnsw' target=\"_blank\">https://wandb.ai/fahmed/precip-VAE/runs/0w6yvnsw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/fahmed/precip-VAE/runs/0w6yvnsw?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f719fb02a00>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"precip-VAE\",\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "    \"architecture\": \"VAE\",\n",
    "    \"dataset\": \"GPM/ERA5\",\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"batch size\":BATCH_SIZE,\n",
    "    \"NN DIM\": NN_DIMS,\n",
    "    \"Latent DIM\": LATENT_DIMS,\n",
    "    \"Predictor\": \"lrh\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "batch 5000\n"
     ]
    }
   ],
   "source": [
    "startTime1 = datetime.now()\n",
    "SAVE_MODEL=True\n",
    "MODEL_NAME_STR='cvae_gamma_conv_rain_singleED_NN=4_LD=2'\n",
    "\n",
    "fig,axx=plt.subplots(1,1,figsize=(6,4))\n",
    "ax=axx\n",
    "losses={'elbo':[],'gamma':[], \n",
    "        'binary':[], 'kl':[]}\n",
    "\n",
    "torch.manual_seed(0)\n",
    "epoch_number = 0\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "syn_size=1_000_000\n",
    "z=torch.normal(mean=0.,std=1.,\n",
    "                            size=(syn_size,LATENT_DIMS))\n",
    "for epoch in range(EPOCHS):\n",
    "    startTime2 = datetime.now()\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    mean_ELBO, mean_gamma_loss, mean_KL_loss, mean_binary_loss\\\n",
    "    = VAE_models_CVAE_one_endec.train_one_epoch(epoch_number,custom_dataloader,model,optimizer)\n",
    "    \n",
    "    losses['elbo'].append(mean_ELBO)\n",
    "    losses['gamma'].append(mean_gamma_loss)\n",
    "    losses['binary'].append(mean_binary_loss)\n",
    "    losses['kl'].append(mean_KL_loss)\n",
    "    \n",
    "    # We don't need gradients on to do reporting\n",
    "    model.train(False)\n",
    "    \n",
    "    VAE_models_CVAE_one_endec.print_params(z,model,torch.tensor([0.8]))\n",
    "\n",
    "    ax.scatter(epoch,mean_ELBO,color='black')\n",
    "    ax.scatter(epoch,mean_gamma_loss,color='red')\n",
    "    ax.scatter(epoch,mean_KL_loss,color='blue')\n",
    "    ax.scatter(epoch,mean_binary_loss,color='orange')\n",
    "    \n",
    "    epoch_number += 1\n",
    "    print(\"Time for epoch: {:.2f} minutes\".format((datetime.now() - startTime2).total_seconds()/60))\n",
    "    \n",
    "    wandb.log({\"ELBO\": mean_ELBO, \"gamma loss\": mean_gamma_loss,\n",
    "              \"binary loss\": mean_binary_loss, \"KL loss\": mean_KL_loss})\n",
    "\n",
    "    \n",
    "    if SAVE_MODEL:\n",
    "        dir_name='/home/fiaz/ML/vae/models/'\n",
    "\n",
    "    #     model_name_prev='cvae_conv_rain_nn_memory_gbeta-bern_{}_epochs.pth'.format(epoch_number-1)\n",
    "    #     model_name='cvae_conv_rain_nn_memory_gbeta-bern_{}_epochs.pth'.format(epoch_number)\n",
    "\n",
    "        model_name_prev=MODEL_NAME_STR+'_{}_epochs.pth'.format(epoch_number-1)\n",
    "        model_name=MODEL_NAME_STR+'_{}_epochs.pth'.format(epoch_number)\n",
    "\n",
    "        if epoch_number>1:\n",
    "            os.remove(dir_name+model_name_prev)\n",
    "        torch.save(model.state_dict(), dir_name+model_name)\n",
    "        print('Model saved as {}'.format(dir_name+model_name))\n",
    "\n",
    "print(\"Total time: {:.2f} minutes\".format((datetime.now() - startTime1).total_seconds()/60))\n",
    "\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst='/home/fiaz/ML/vae/models/cvae_gamma_conv_rain_singleED_50_epochs.pth'\n",
    "# dst='/home/fiaz/ML/vae/models/cvae_gamma_conv_rain_singleED_NN=4_LD=1_48_epochs.pth'\n",
    "model.load_state_dict(torch.load(dst))\n",
    "VAE_models_CVAE_one_endec.print_params(z,model,torch.tensor([0.8]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp_bins=2**(np.arange(-2.,8.125,0.125))\n",
    "pcp_bins=np.insert(pcp_bins,0,1e-3)\n",
    "pcp_bin_center=(pcp_bins[1:]+pcp_bins[:-1])*0.5\n",
    "dx=np.diff(pcp_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "colors_norm = matplotlib.colors.Normalize(vmin=0, vmax=1.)\n",
    "cmap = plt.get_cmap('YlOrRd')\n",
    "col = matplotlib.cm.ScalarMappable(norm=colors_norm, cmap=cmap)\n",
    "\n",
    "colors_norm = matplotlib.colors.Normalize(vmin=-3, vmax=3.)\n",
    "colz = matplotlib.cm.ScalarMappable(norm=colors_norm, cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_size=1_000_00\n",
    "synthetic_input=torch.normal(mean=0.,std=1.,\n",
    "                            size=(syn_size,LATENT_DIMS))\n",
    "\n",
    "\n",
    "fig,axx=plt.subplots(2,2,figsize=(8.,5.))\n",
    "\n",
    "for i in np.arange(0,0.95,.05):    \n",
    "#     synthetic_input[:,0]=2\n",
    "    synthetic_input[:]=3.\n",
    "\n",
    "    crh_cond=torch.ones([syn_size,1])\n",
    "    crh_cond[:]=i\n",
    "    \n",
    "    log_alpha,log_beta, prob=model.decoder(synthetic_input,crh_cond)\n",
    "    m1=torch.distributions.Gamma(log_alpha.exp(),log_beta.exp())\n",
    "    m2=torch.distributions.Bernoulli(prob)\n",
    "    \n",
    "    prc_array= (m2.sample()*m1.sample()*prc_norm).numpy().squeeze()\n",
    "    \n",
    "    prc_hist=np.histogram(prc_array,bins=pcp_bins)[0]\n",
    "    prc_hist=prc_hist/(dx*prc_hist.sum())\n",
    "    \n",
    "    axx[0,0].scatter(pcp_bin_center,prc_hist,color=col.to_rgba(i))\n",
    "    axx[0,1].hist(prob.detach().numpy().squeeze(),color=col.to_rgba(i))\n",
    "    \n",
    "for i in np.arange(-3,3.2,0.2):\n",
    "    \n",
    "#     synthetic_input[:,0]=i\n",
    "    synthetic_input[:]=i\n",
    "\n",
    "    crh_cond=torch.ones([syn_size,1])\n",
    "    crh_cond[:]=0.8\n",
    "    \n",
    "    log_alpha,log_beta, prob=model.decoder(synthetic_input,crh_cond)\n",
    "    m1=torch.distributions.Gamma(log_alpha.exp(),log_beta.exp())\n",
    "    m2=torch.distributions.Bernoulli(prob)\n",
    "    \n",
    "    prc_array= (m2.sample()*m1.sample()*prc_norm).numpy().squeeze()\n",
    "    \n",
    "    prc_hist=np.histogram(prc_array,bins=pcp_bins)[0]\n",
    "    prc_hist=prc_hist/(dx*prc_hist.sum())\n",
    "    \n",
    "    axx[1,0].scatter(pcp_bin_center,prc_hist,color=colz.to_rgba(i))\n",
    "    axx[1,1].hist(prob.detach().numpy().squeeze(),color=colz.to_rgba(i))\n",
    "    \n",
    "    \n",
    "axx[0,0].set_yscale('log')\n",
    "axx[1,0].set_yscale('log')\n",
    "axx[0,0].set_xlim(0,150)\n",
    "axx[1,0].set_xlim(0,150)\n",
    "\n",
    "for ax in axx[0]:\n",
    "    ax.tick_params(which='both',labelsize=13)\n",
    "\n",
    "for ax in axx[1]:\n",
    "    ax.tick_params(which='both',labelsize=13)\n",
    "\n",
    "# axx[0,1].set_xlabel('Shape',fontsize=13)\n",
    "# axx[1,1].set_xlabel('Scale',fontsize=13)\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def set_seed(seed: int = 42) -> None:\n",
    "#     np.random.seed(seed)\n",
    "#     random.seed(seed)\n",
    "#     torch.manual_seed(seed)\n",
    "#     torch.cuda.manual_seed(seed)\n",
    "#     # When running on the CuDNN backend, two further options must be set\n",
    "#     torch.backends.cudnn.deterministic = True\n",
    "#     torch.backends.cudnn.benchmark = False\n",
    "#     # Set a fixed value for the hash seed\n",
    "#     os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "#     print(f\"Random seed set as {seed}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
